{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 - Méthodes probabilistes et statistiques pour I.A.\n",
    "#### Polytechnique Montréal\n",
    "\n",
    "\n",
    "### Projet A2023\n",
    "\n",
    "-----\n",
    "\n",
    "# Prix des diamants\n",
    "\n",
    "### Contexte\n",
    "\n",
    "Dans le cadre du projet du cours MTH3302 on réalise une Prédiction du prix de vente des diamants. Cet ensemble classique de données classique contient les prix les caractéristiques de près de 54 000 diamants. Il s'agit d'un ensemble de données idéal pour mettre en pratique les modèles statistiques vus en MTH3302 !\n",
    "\n",
    "### Objectif\n",
    "\n",
    "Notre objectif est de construire un modèle prédictif pour prédire les prix des diamants selon leurs propriétés physiques, tels que leur qualité de coupe, leur couleur, leur clarité, ainsi que leurs dimensions.\n",
    "\n",
    "### Données\n",
    "\n",
    "Les données sont constituées des fichiers suivants :\n",
    "\n",
    "- `train.csv`\n",
    "- `test.csv`\n",
    "\n",
    "On utilise le fichier train.csv qui contient le prix de vente en dollar américain de 40 455 diamants en fonction des caractéristiques suivantes :\n",
    "\n",
    "- `cut` : qualité de coupe (Fair, Good, Very Good, Premium, Ideal)\n",
    "- `color` : couleur du diamant (de J (pire) à D (meilleure)\n",
    "- `clarity` : clarté du diamant (I1 (pire), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (meilleure))\n",
    "- `x`: longueur en mm\n",
    "- `y`: largeur en mm\n",
    "- `z`: profondeur en mm\n",
    "- `depth`: pourcentage de la profondeur exprimée comme 2*z/(x+y)\n",
    "- `table`: pourcentage de la largeur du sommet du diamant par rapport au point le plus large\n",
    "\n",
    "Le fichier test.csv contient les caractéristiques de 13 485 diamants pour lesquels vous devriez prédire le prix de vente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Importation des librairies utilisées dans le calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Random, MLBase, Gadfly, GLM, Statistics, Distributions, StatsBase, StatsModels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "data_train_filename = joinpath(data_dir, \"train.csv\")\n",
    "data = CSV.read(data_train_filename, DataFrame)\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données des diamants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_filename = joinpath(data_dir, \"test.csv\")\n",
    "test = CSV.read(data_test_filename, DataFrame)\n",
    "first(test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données du test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Exploratoire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, nous allons nous familiariser avec les données afin de voir comment chaque propriété affecte le prix et de chercher les données manquantes ainsi que détecter les données abérantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description des variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le tableau ci-dessus, nous permet de constater que:\n",
    "\n",
    "- Le minimum de la variable de mesure x est zéro.\n",
    "- Le minimum de la variable de mesure y est -0.02.\n",
    "- Le minimum de la variable de mesure z est zéro.\n",
    "\n",
    "\"x\",\"y\" et \"z\" doivent être des valeurs plus grande que zéro, car elles définissent des mesures. Puisqu'elles sont fausses, il faut les filtrer de sorte à garder que les mesures positives. On remarque aussi qu'il y a 2200 valeurs de mesures \"y\" et de \"depth\" manquantes. On verra comment elles seront traiter plus loin dans le rapport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prix en fonction de x, y et z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.set_default_plot_size(27.5cm, 10cm)\n",
    "hstack(\n",
    "    plot(data, x=:x, y=:price, Geom.point, Guide.title(\"Prix en fonction de x\")),\n",
    "    plot(data, x=:y, y=:price, Geom.point, Guide.title(\"Prix en fonction de y\")),\n",
    "    plot(data, x=:z, y=:price, Geom.point, Guide.title(\"Prix en fonction de z\")),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces graphiques permettent de déceler une certaine corrélation positive entre les mesures de x, y et z et le prix du diamant. Cette corrélation semble particulièrement forte. Ceci est logique, car la mesure du diamant a un impact important sur le prix. Cependant, il y a quelques valeurs extrêmes qu'on doit traiter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prix en fonction du depth et de table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.set_default_plot_size(27.5cm, 10cm)\n",
    "hstack(\n",
    "    plot( dropmissing(data, :depth), y=:price, x=:depth, Geom.histogram, Guide.title(\"Prix en fonction de depth\")),\n",
    "    plot(data, y=:price, x=:table, Geom.histogram, Guide.title(\"Prix en fonction de table\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prix en fontion de la qualité de coupe, de la couleur du diamant et de la clarté du dianmant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.set_default_plot_size(27.5cm, 30cm)\n",
    "sort_color = sort(data, :color)\n",
    "vstack(\n",
    "    plot(dropmissing(data[:, [:cut, :price]]), y=:price, x=:cut, Geom.boxplot, Guide.title(\"Prix en fonction de la qualité de coupe\")),\n",
    "    plot(sort_color, y=:price, x=:color, Geom.boxplot, Guide.title(\"Prix en fonction de la couleur\")),\n",
    "    plot(data, y=:price, x=:clarity, Geom.boxplot, Guide.title(\"Prix en fonction de la clarté\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgré quelques valeurs abérantes, on remarque une distribution normale du prix dans les deux cas. \n",
    "On remarque que la courbe donnant le prix en fonction de $depth$ est légèrement étendue vers la gauche, tandis que celle donnant le prix en fonction de $table$ est légèrement étendue vers la droite. Cependant ce déséquilibre est très léger.\n",
    "\n",
    "De manière générale, les variables $depth$ et $table$ ne semblent pas avoir une grande corrélation avec le prix d'un diamant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largeur (y) en fonction de la longueur (x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux valeurs étant des mesures des dimensions d'un diamant pourraient avoir une corrélation qui aiderait à prédire les valeurs de largeur manquantes. Regardons le graphique suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(data, x=:x, y=:y, Geom.point, Guide.title(\"Largeur en fonction de la Longueur\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regardant le graphique ci-dessus, nous pouvons voir une forte relation linéaire entre les valeurs de x et y. Ainsi, nous pouvons appliquer une régression linéaire simple afin de prédire les valeurs manquantes de y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données abérantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche ici à écarter les valeurs abérantes, c'est-à-dire les valeurs qui sont isolées et extrêmement loin des autres valeurs. Ces données pourraient avoir une forte influence et potentiellement fausser nos prédictions.  \n",
    "\n",
    "Pour cela, on sélectionne les valeurs qui sont à une distance de 1.5 fois l'écart interquartile, soit avant le 1er quartile, soit après le 3e quartile. Notre fonction $upperLowerTrail()$ nous permet de trouver les bornes de notre intervalle acceptant. Nous allons ensuite remplacer les données aberrantes par les limites de l'intervalle de confiance afin de maximiser la quantité de données à notre disposition à l'aide de la fonction $replaceExtremeValues()$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the upper and lower tails of a column\n",
    "function upperLowerTrail(data::DataFrame, column::Symbol)\n",
    "    IQR = iqr(data[!, column])\n",
    "    q1 = percentile(data[!, column], 25)\n",
    "   \n",
    "    q3 = percentile(data[!, column], 75)\n",
    "    upper_tail = round(q3 + IQR *1.5, digits = 2)\n",
    "    lower_tail = round(q1 - IQR *1.5, digits = 2)\n",
    "    \n",
    "    println(\"INF : \" ,lower_tail)\n",
    "    println(\"SUP : \" ,upper_tail)\n",
    "\n",
    "    return upper_tail, lower_tail\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function replaceExtremeValues(dataFrame::DataFrame, column::Symbol)\n",
    "    upper_tail, lower_tail = upperLowerTrail(dataFrame, column)\n",
    "    col = dataFrame[!, column]\n",
    "    col = map(x -> if x > upper_tail upper_tail elseif x < lower_tail lower_tail else x end, col)\n",
    "    dataFrame[!, column] = col\n",
    "    return dataFrame\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données abérantes de x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitons maintenant les valeurs abérantes de x. En trouvant l'intervalle de confiance, nous trouvons que la borne inférieure est de 1.96 et la borne supérieure de 9.28. Nous allons remplacer les données abérantes par celles-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(data, :x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données abérantes de y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir calculer l'intervalle de confiance pour les valeurs de y, nous devons enlever les données manquantes. Cependant, nous allons dupliquer l'ensemble d'entraînement et retirer les valeurs manquantes afin de ne pas perdre les lignes dans celle-ci.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clone = data[.!ismissing.(data.y), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(data_clone, :y)\n",
    "describe(data_clone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données abérantes de z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons 22 données de y abérantes. On va donc les retirer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(data, :z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données abérantes de depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vue qu'il y a beaucoup de donnés et que le depth est un pourcentage qui est calculé à partir des valeurs de mesures x,y et z. Nous ne pouvons pas les enelver. Cependant on peut trouver un moyen pour corriger certaines données qui sont fausses grâce à l'équation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données abérantes de table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données de la variables tables sont des rapports, il faut voir comment elles agissent sur le prix. On va tester avec et sans ces valeurs pour déterminer la meilleure approche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(data, :table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a des données manquantes pour les variables y et depth. La variable depth dépend des données de y, car elle est calculée à partir de l'équation, 2*z/(x+y). Ainsi, en corrigeant y, on peut recalculer le depth avec l'équation. Grâce à la linéarité entre x et y, nous allons appliquer une régression linéaire simple afin de déduire les valeurs de y manquantes. La création de ce modèle de régression linéaire simple se trouve dans la fonction $predictMissingY()$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predictMissingY(dataframe::DataFrame, dataToChange::DataFrame)\n",
    "    # Extraction des données dans des vecteurs\n",
    "    x₁ = dataframe[!, :x]\n",
    "    y = dataframe[!, :y]\n",
    "\n",
    "    # Calcul des statistiques utiles\n",
    "    n = length(y)\n",
    "    x̄₁ = mean(x₁)\n",
    "    ȳ = mean(y)\n",
    "\n",
    "    # Calcul des coefficients de régression (pente et ordonnée à l'origine)\n",
    "    β̂₁ = sum((x₁[i] - x̄₁)*(y[i] - ȳ)  for i=1:n) / sum( (x₁[i] - x̄₁)^2 for i=1:n)\n",
    "    β̂₀ = ȳ - β̂₁*x̄₁\n",
    "\n",
    "    # Calcul des résidus\n",
    "    SSE = sum((y[i] - β̂₀ - β̂₁*x₁[i])^2 for i=1:n)\n",
    "    SST = sum((y[i] - ȳ)^2 for i=1:n)\n",
    "    SSR = sum((y[i] - β̂₀ - β̂₁*x₁[i])^2 for i=1:n)\n",
    "\n",
    "    # Calcul du coefficient de détermination\n",
    "    R² = 1 - SSR/SST\n",
    "    println(\"R² = \", R²)\n",
    "                        \n",
    "    for row in eachrow(dataToChange)\n",
    "    # Check if the y value is missing\n",
    "        if ismissing(row[:y])\n",
    "            # Predict the y value using the estimated coefficients\n",
    "            row[:y] = round(β̂₀ + β̂₁ * row[:x], digits = 2)\n",
    "#             row[:depth] = round((2 * row[:z] / (abs(row[:x]) + abs(row[:y]))) * 100, digits=1 )\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictMissingY(data_clone, data)\n",
    "replaceExtremeValues(data, :y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut à présent utiliser les valeurs extimées de $y$ pour estimer à leur tour les valeurs manquantes de $depth$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function replaceMissingDepth(dataframe::DataFrame)\n",
    "    for i in 1:nrow(dataframe)\n",
    "        if ismissing(dataframe[i, :depth]) || isnan(dataframe[i, :depth])\n",
    "            dataframe[i, :depth] = round(2 * (dataframe[i, :z] / (dataframe[i, :x]+dataframe[i, :y]) ) * 100, digits=1)\n",
    "        end\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceMissingDepth(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(data, :depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " À présent, on doit traiter les valeurs manquantes de la variable explicative $cut$. D'abord, on encode la variable $cut$ qui est qualitative pour pouvoir la traiter. Puis, on va aussi faire une régression. La fonction $predictMissingCut()$ permet de choisir les meilleures variables explicatives de cut pour ensuite créer le meilleur modèle pour prédire les valeurs manquantes de cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkScore(df::DataFrame, θ̂ ::Array{Float64})\n",
    "    score = 0;\n",
    "    best_threshold = 0;\n",
    "    cut_pred = round.(θ̂ )\n",
    "    for i in 1:length(df.cut)\n",
    "        if (cut_pred[i] == df.cut[i])\n",
    "            score = score + 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return score\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function findBestFormulaCut(data_frame::DataFrame, variables::Vector{Symbol})\n",
    "    current_variables = Symbol[]\n",
    "    best_formula, max_area = nothing, 0.0\n",
    "    variable_count = length(variables)\n",
    "\n",
    "    for i in 1:variable_count\n",
    "        current_max_area = 0.0\n",
    "        best_current_variable_index, best_current_formula = -1, nothing\n",
    "\n",
    "        for (j, variable) in enumerate(variables)\n",
    "            if (length(current_variables) != 0)\n",
    "                formula = Term(:cut) ~ sum(Term(current_variables[k]) for k in 1:length(current_variables)) + Term(variables[j])\n",
    "                p =  length(current_variables)\n",
    "            else\n",
    "                formula = Term(:cut) ~ Term(variables[j])\n",
    "                p = 1 \n",
    "            end\n",
    "            \n",
    "            M = lm(formula, data_frame)\n",
    "            θ̂ = convert(Vector{Float64}, predict(M, data_frame))\n",
    "            area = checkScore(data_frame, θ̂)\n",
    "\n",
    "            if area > current_max_area\n",
    "                current_max_area = area\n",
    "                best_current_variable_index = j\n",
    "                best_current_formula = formula\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if current_max_area > max_area\n",
    "            max_area = current_max_area\n",
    "            best_formula = best_current_formula\n",
    "            push!(current_variables, variables[best_current_variable_index])\n",
    "            deleteat!(variables, best_current_variable_index)\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return best_formula\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function replaceMissingCut(data::DataFrame) \n",
    "    df_cut = dropmissing(data)\n",
    "    # Créer les mappings pour chaque variable catégorielle\n",
    "    cut_mapping = Dict(\"Fair\" => 1, \"Good\" => 2, \"Very Good\" => 3, \"Premium\" => 4, \"Ideal\" => 5)\n",
    "\n",
    "    # Appliquer les mappings à chaque colonne\n",
    "    df_cut[!, :cut] = map(x -> cut_mapping[x], df_cut[!, :cut])\n",
    "\n",
    "    variables_cut = propertynames(select(df_cut, Not([:ID, :cut])))\n",
    "    best_formula_cut = findBestFormulaCut(df_cut, variables_cut)\n",
    "    \n",
    "    M_cut = lm(best_formula_cut, df_cut)\n",
    "    \n",
    "    # Extract the rows with missing values\n",
    "    missing_rows = ismissing.(data[!, :cut])\n",
    "    missing_rows_indexes = findall(missing_rows)\n",
    "\n",
    "    # Predict missing values only for rows with missing values\n",
    "    predicted_values = predict(M_cut, data[missing_rows_indexes, setdiff(names(data), [:cut])])\n",
    "\n",
    "    # Replace missing values with predicted values\n",
    "    predicted_cuts = round.(predicted_values)\n",
    "    for i in 1:length(missing_rows_indexes)\n",
    "        cut = predicted_values[i]\n",
    "        if(cut >= 0 && cut <= 1 )\n",
    "            data[missing_rows_indexes[i], :cut] = \"Fair\"\n",
    "        elseif(cut > 1 && cut <= 2 )\n",
    "            data[missing_rows_indexes[i], :cut] = \"Good\"\n",
    "        elseif(cut >2 && cut <= 3 )\n",
    "            data[missing_rows_indexes[i], :cut] = \"Very Good\"\n",
    "        elseif(cut > 3 && cut <= 4 )\n",
    "            data[missing_rows_indexes[i], :cut] = \"Premium\"\n",
    "        else\n",
    "            data[missing_rows_indexes[i], :cut] = \"Ideal\"\n",
    "        end \n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceMissingCut(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite à la prédiction de cut, on peut voir qu'on a plus de valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données\n",
    "\n",
    "Afin de traiter plus facilement nos données, on veut pouvoir les standardiser. Ceci permet de mettre toutes nos variables explicatives sur la même échelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standardize_data(data::DataFrame, cols_standarize::Vector{String})\n",
    "    # Column names\n",
    "    col_names = names(data)\n",
    "\n",
    "    # Convert column names to indices\n",
    "    name_to_index = Dict(zip(col_names, 1:length(col_names)))\n",
    "\n",
    "    # Select columns to standardize by name\n",
    "    data_to_standarize = data[:, [name_to_index[col] for col in cols_standarize]]\n",
    "\n",
    "    # Fit a Z-score transformation to the selected columns\n",
    "    dt = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(data_to_standarize), dims=1)\n",
    "    \n",
    "    # Transform the selected columns using the Z-score transformation\n",
    "    standard_data = StatsBase.transform(dt, Matrix{Float64}(data_to_standarize))\n",
    "    \n",
    "    return standard_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_standarize = [\"x\", \"y\", \"z\", \"depth\", \"table\"]\n",
    "standard_data = standardize_data(data, cols_standarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données catégoriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable cut est la seule qui possède des données manquantes. Nous avons décidé de les remplacer par des données qui possèdent à peu près les mêmes caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on remarque comme deux courbes. Le volume est donc une bonne variable discriminante. Ceci nous conforte dans notre choix de garder cette nouvelle variable explicative, elle nous sera utile pour construire notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout des colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pense qu'une nouvelle variable explicative, à savoir le volume du diamant, serait pertinente. Pour cela, on doit d'abord calculer le carré de chacune des dimensions $x$, $y$ et $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x^2, y^2, z^2, x^3, y^3, z^3, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,cols_standarize] = standard_data\n",
    "data[:, :x²] = (data.x).^2\n",
    "data[:, :y²] = (data.y).^2\n",
    "data[:, :z²] = (data.z).^2\n",
    "data[:, :x³] = (data.x).^3\n",
    "data[:, :y³] = (data.y).^3\n",
    "data[:, :z³] = (data.z).^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function diamond_volume(x, y, z, depth, table)\n",
    "    volume = (x * y * z * (1 - depth / 100) * (1 - table / 100)) \n",
    "    return volume\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.volume = diamond_volume.(data.x, data.y, data.z, data.depth, data.table)\n",
    "data.volume² = (data.volume).^2\n",
    "data.volume³ = (data.volume).^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.set_default_plot_size(20cm, 15cm)\n",
    "Gadfly.plot(data, x=\"volume\", y=\"price\", Geom.point,  \n",
    "    Guide.xlabel(\"Volume\"), \n",
    "    Guide.ylabel(\"Price\"), \n",
    "    Guide.title(\"Diamond Price vs. Volume\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitionnement des données en ensemble d'entraînement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3302)\n",
    "train_id = sample(1:nrow(data), round(Int, .8*nrow(data)), ordered=true, replace=false)\n",
    "valid_id = setdiff(1:nrow(data), train_id)\n",
    "\n",
    "train = data[train_id,:]\n",
    "valid = data[valid_id,:]\n",
    "describe(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainnement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function findBestThreshold(df::DataFrame, ŷ::Vector{Union{Missing, Float64}}, p::Int64)\n",
    "    y = df.price\n",
    "    ȳ = mean(y)\n",
    "    SST = sum((y .- ȳ).^2)\n",
    "    n = length(y)\n",
    "    e = y-ŷ\n",
    "    SSE = e'*e\n",
    "    R²aj =  1 - SSE/SST * (n-1)/(n-p)\n",
    "    \n",
    "    return R²aj\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function forwardStepwiseRegressionThreshold(data_frame::DataFrame, variables::Vector{Symbol})\n",
    "    current_variables = Symbol[]\n",
    "    max_area = 0.0\n",
    "    best_formula = nothing\n",
    "\n",
    "    for i in 1:length(variables)\n",
    "        current_max_area = 0.0\n",
    "        best_current_variable_index = -1\n",
    "        best_current_formula = nothing\n",
    "        \n",
    "        for j in 1:length(variables)\n",
    "            \n",
    "            if (length(current_variables) != 0)\n",
    "                formula = Term(:price) ~ sum(Term(current_variables[k]) for k in 1:length(current_variables)) + Term(variables[j])\n",
    "                p =  length(current_variables)\n",
    "            else\n",
    "                formula = Term(:price) ~ Term(variables[j])\n",
    "                p = 1 \n",
    "            end\n",
    "            \n",
    "            M = lm(formula, data_frame)\n",
    "            θ̂ = predict(M, data_frame)\n",
    "            area = findBestThreshold(data_frame, θ̂, p)\n",
    "            \n",
    "            if area > current_max_area\n",
    "                current_max_area = area\n",
    "                best_current_variable_index = j\n",
    "                best_current_formula = formula\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if current_max_area > max_area\n",
    "            max_area = current_max_area\n",
    "            best_formula = best_current_formula\n",
    "            push!(current_variables, variables[best_current_variable_index])\n",
    "            deleteat!(variables, best_current_variable_index)\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return best_formula\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_reg_model(dataframe::DataFrame)    \n",
    "    variables = propertynames(select(dataframe, Not([:ID, :price])))\n",
    "    best_formula = forwardStepwiseRegressionThreshold(dataframe, variables)\n",
    "    return best_formula\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Decrire la focntion best_formula et interpréter la formule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_formula = train_reg_model(data)\n",
    "println(\"Meilleur variables \", best_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = lm(best_formula, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction à partir des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions locales - ensemble de validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédictions locales - ensemble de validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modèles d'essaies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_model(M, valid::DataFrame, θ̂_valid)\n",
    "    # Get the number of predictor variables used in the model\n",
    "    p = length(names(valid)) - 1\n",
    "    \n",
    "    y = valid.price\n",
    "    e = θ̂_valid - y\n",
    "    \n",
    "    # Calculate the total sum of squares (SST)\n",
    "    ȳ = mean(y)\n",
    "    SST = sum((y .- ȳ).^2)\n",
    "    \n",
    "    # Calculate the residual sum of squares (SSE)\n",
    "    SSE = sum(e .^ 2)\n",
    "    \n",
    "    # Calculate the adjusted R-squared value\n",
    "    n = length(y)\n",
    "    R²aj = 1 - SSE / SST * (n - 1) / (n - p)\n",
    "    \n",
    "    # Calculate the mean squared error (MSE)\n",
    "    MSE = sqrt(mean(e .^ 2))\n",
    "    \n",
    "    return (R²aj = R²aj, MSE = MSE)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ̂_valid = abs.(predict(M, valid))\n",
    "\n",
    "result = evaluate_model(M, valid, θ̂_valid)\n",
    "println(\"Adjusted R-squared: \", result.R²aj)\n",
    "println(\"MSE: \", result.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = DataFrame(ID = valid.ID, price_real = valid.price , price_pred = θ̂_valid)\n",
    "prediction.Ecart = abs.(prediction.price_real - prediction.price_pred)\n",
    "show(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_neg = filter(row -> row[:price_pred] <= 0 , prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price prédit négativement à analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_pred_neg = innerjoin(data,pred_neg , on=:ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions kaggle - ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_filename = joinpath(data_dir, \"test.csv\")\n",
    "test = CSV.read(data_test_filename, DataFrame)\n",
    "describe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = replaceExtremeValues(test, :x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clone = test[.!ismissing.(test.y), :]\n",
    "replaceExtremeValues(test_clone, :y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictMissingY(test_clone, test)\n",
    "replaceExtremeValues(test, :y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(test, :z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(test, :table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceMissingDepth(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceExtremeValues(test, :depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceMissingCut(test)\n",
    "\n",
    "describe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_data = standardize_data(test, cols_standarize)\n",
    "\n",
    "test[:,cols_standarize] = standard_data\n",
    "test[:, :x²] = (test.x).^2\n",
    "test[:, :y²] = (test.y).^2\n",
    "test[:, :z²] = (test.z).^2\n",
    "test[:, :x³] = (test.x).^3\n",
    "test[:, :y³] = (test.y).^3\n",
    "test[:, :z³] = (test.z).^3\n",
    "\n",
    "test.volume = diamond_volume.(test.x, test.y, test.z, test.depth, test.table) \n",
    "test.volume² = (test.volume).^2\n",
    "test.volume³ = (test.volume).^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ̂ = abs.(predict(M, test))\n",
    "prediction = DataFrame(ID = test.ID, price = θ̂ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(prediction,20)\n",
    "CSV.write(\"../data/benchmark_predictions.csv\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et améliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pistes avortées\n",
    "\n",
    "\n",
    "#### Conclusion \n",
    "\n",
    "\n",
    "#### Améliorations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
